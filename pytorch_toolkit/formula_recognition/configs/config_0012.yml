backbone_config:
  type: VGG
  in_channels: 1
head:
  type: LSTMEncoderDecoder
val_transforms_list:
  - name: TransformGrayscale
device: "cuda"
model_path: 0012/model_checkpoints/loss_test_best_model_2021-01-27_16-38-32.pth
vocab_path: /media/cluster_fs/user/vloginov/im2latex_project/vocabs/vocab_alphanumeric.json
train:
  batch_size: 4
  learning_rate: 0.0001
  log_path: 0012/logs
  clip_grad: 2.5
  epochs: 10
  loss_type: CTC
  CTCLossZeroInf: true
  save_freq: 100000
  val_freq: 50000
  print_freq: 64
  optimizer: Adam
  save_dir: model_checkpoints
  datasets:
    - type: MJSynthDataset
      data_folder: /home/vloginov/work/90kDICT32px
      annotation_file: annotation_train.txt
      case_sensitive: false
      fixed_img_shape:
        - 32
        - 120
      subset: train
    - type: ICDAR2013RECDataset
      case_sensitive: false
      images_folder: Challenge2_Training_Task3_Images
      annotation_file: Challenge2_Training_Task3_Images/gt.txt
      root: /home/vloginov/work/
      fixed_img_shape:
        - 32
        - 120
      grayscale: true
      subset: validate
  train_transforms_list:
    - name: TransformGrayscale
    # - name: TransformRescale
    #   scale_min: 0.8
    #   scale_max: 2
    # # - name: ColorJitter
    # - name: TransformResize
    #   target_shape:
    #     - 32
    #     - 120
eval:
  dataset:
    type: ICDAR2013RECDataset
    case_sensitive: false
    images_folder: /home/vloginov/work/omz_validation_datasets/ICDAR13_REC/Challenge2_Test_Task3_Images
    annotation_file: /home/vloginov/work/omz_validation_datasets/ICDAR13_REC/gt/gt.txt.fixed.alfanumeric.greater3
    grayscale: true
    fixed_img_shape:
      - 32
      - 120
  render: false
  use_ctc: true
demo:
  transforms_list: []
export:
  res_encoder_name: medium_v2_encoder.onnx
  res_decoder_name: medium_v2_decoder.onnx
  export_ir: true
  verbose_export: false
  input_shape_decoder:
    - 1
    - 3
    - 65
    - 1450
